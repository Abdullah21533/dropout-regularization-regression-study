# Evaluating the Impact of Dropout Regularization on Neural Network Regression Performance

This repository contains a comparative study of two feedforward neural networks: one with dropout regularization and one without. Using synthetic regression data, the models are trained and evaluated to observe the effects of dropout on overfitting and generalization.

## üîç Key Features
- Implementation in TensorFlow/Keras
- Training on synthetic X-Y regression dataset
- Comparison of model performance (MSE, prediction plots)
- Visualizations: data distribution, prediction curves, loss curves

## üìä Results
| Model               | Train MSE | Test MSE |
|--------------------|-----------|----------|
| Without Dropout    | 0.0123    | 0.0198   |
| With Dropout       | 0.0156    | 0.0161   |

## üß† Technologies Used
- Python 3.x
- TensorFlow / Keras
- NumPy
- Matplotlib

---

Contributions welcome!
